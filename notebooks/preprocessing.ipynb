{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook is for preprocessing the data and getting it ready to be clustered. This is done by exploring the data, getting rid of outliers, \n",
    "and converting data to binary to only check for presence of a feature. I chose to use a variance threshhold for some feature reduction by only \n",
    "getting rid of features where all values were identical. If a feature is just the exact same (present or not present) for every sample of data, it \n",
    "contriubutes nothing but noise. I chose not to use Principal Componenet Analysis (PCA) because it assumes the data is continuouse, not binary, causing \n",
    "potential issues due to assumptions. Multiple Correspondence Analysis (MCA) would also work for dimensionality reduction, but would likely cause a loss \n",
    "in information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c04b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to see value counts of each column. The builtin value_counts function in the pandas libary is hard to read, so with val_count, it makes it a bit easier\n",
    "\n",
    "def val_count(data):\n",
    "    counter = 0\n",
    "    for i in data.columns:\n",
    "        print(counter)\n",
    "        print(data[i].value_counts())\n",
    "        counter += 1\n",
    "        print(\"==========================\"*5)\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfb7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of outliers and duplicates\n",
    "\n",
    "df = df.drop(columns= df.columns[153:].tolist(), axis = 1) #dropped because features were unamed and VERY sparse\n",
    "df = df.drop_duplicates()\n",
    "df = df.drop([46341,40941]) #outliers\n",
    "df[\"Complete\"] = df[\"Complete\"].replace(\"TRUE\", True )\n",
    "df[\"Complete\"] = df[\"Complete\"].replace(\"FALSE\", False )\n",
    "df[\"properties_trace_trace_feature\"] = df[\"properties_trace_trace_feature\"].replace(\"TRUE\", True )\n",
    "df[\"properties_inferences_outcrop_in_place\"] = df[\"properties_inferences_outcrop_in_place\"].replace(\"5 - definitely in place\", 5 )\n",
    "df[\"properties_symbology_lineWidth\"] = df[\"properties_symbology_lineWidth\"].replace(2.0,\"2\")\n",
    "df[\"properties_symbology_lineWidth\"] = df[\"properties_symbology_lineWidth\"].replace(4.0,\"4\")\n",
    "df = df.dropna(axis=1, how= \"all\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped to prevent data leakage. These features were added in at a later point in time as indicated by their values which are grades of the spots.\n",
    "\n",
    "df = df.drop(columns= [\"contacts drawing\", \"contacts drawing quality\", \"classification of spots\" , \"correctness of spots\", \"completeness of map\",\"unit labels\",  \"images\", \"overall impression\", \"Complete\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d143e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_simplification(df):\n",
    "    \"\"\"converts a pandas dataframe into binary based off of presence in data\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): a pandas dataframe of the data that needs to be converted to binary\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: a new dataframe that has now been converted to binary\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    binary_col_data = {}\n",
    "    columns_to_drop = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        print(f\"Converting {col} to binary\")\n",
    "        binary_col_data[col] = df_new[col].replace('', np.nan).notna().astype(int)\n",
    "        columns_to_drop.append(col)\n",
    "            \n",
    "    df_new = df_new.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Add all new binary columns in one go using pd.concat\n",
    "    if binary_col_data:\n",
    "        df_new = pd.concat([df_new, pd.DataFrame(binary_col_data, index=df_new.index)], axis=1)\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b390ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = binary_simplification(df)\n",
    "val_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c26589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses variance threshold for feature reduction, removes features where all values are identical\n",
    "\n",
    "selector = VarianceThreshold(threshold=0) #removes all features with low variance in 100% of samples  (you do (1 - percentage of same values) * percentage of vaues that are the same)\n",
    "selector.fit_transform(df)\n",
    "\n",
    "cols_idxs = selector.get_support(indices=True)\n",
    "df = df.iloc[:,cols_idxs]\n",
    "val_count(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0dfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed_data.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
